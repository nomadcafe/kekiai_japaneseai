#!/usr/bin/env python3
import json
import subprocess
import os
from pathlib import Path
from dialogue_video_creator_fixed import DialogueVideoCreatorFixed

class SmartVideoCreator:
    def __init__(self):
        self.fallback_strategies = [
            ("åŸºæœ¬ç‰ˆ", self.create_basic_video),
            ("ç°¡å˜ãªéŸ³å£°çµåˆç‰ˆ", self.create_simple_concat_video),
            ("å€‹åˆ¥ã‚¹ãƒ©ã‚¤ãƒ‰ç‰ˆ", self.create_individual_slide_video)
        ]
    
    def check_video_integrity(self, video_path):
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run([
                'ffprobe', '-v', 'error', '-show_format', '-show_streams', video_path
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0 and 'moov atom not found' not in result.stderr:
                print(f"âœ… å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« {video_path} ã¯æ­£å¸¸ã§ã™")
                return True
            else:
                print(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« {video_path} ã«å•é¡ŒãŒã‚ã‚Šã¾ã™: {result.stderr}")
                return False
        except Exception as e:
            print(f"âŒ å‹•ç”»ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def create_basic_video(self, image_paths, dialogue_audio_info, output_path):
        """åŸºæœ¬çš„ãªå‹•ç”»ä½œæˆæ–¹æ³•"""
        print("ğŸ“¹ åŸºæœ¬ç‰ˆã§å‹•ç”»ä½œæˆä¸­...")
        video_creator = DialogueVideoCreatorFixed()
        return video_creator.create_dialogue_video(image_paths, dialogue_audio_info, output_path)
    
    def create_simple_concat_video(self, image_paths, dialogue_audio_info, output_path):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°çµåˆã§ã®å‹•ç”»ä½œæˆ"""
        print("ğŸ“¹ ç°¡å˜ãªéŸ³å£°çµåˆç‰ˆã§å‹•ç”»ä½œæˆä¸­...")
        from moviepy.editor import ImageClip, AudioFileClip, concatenate_audioclips, concatenate_videoclips
        
        clips = []
        for i, image_path in enumerate(image_paths):
            slide_key = f"slide_{i+1}"
            audio_infos = dialogue_audio_info.get(slide_key, [])
            
            # ç”»åƒã‚¯ãƒªãƒƒãƒ—ã‚’ä½œæˆ
            image_clip = ImageClip(image_path)
            
            if audio_infos:
                # ã™ã¹ã¦ã®éŸ³å£°ã‚’å˜ç´”ã«çµåˆï¼ˆç„¡éŸ³ãªã—ï¼‰
                audio_clips = []
                for info in audio_infos:
                    if info.get("audio_path") and Path(info["audio_path"]).exists():
                        audio_clip = AudioFileClip(info["audio_path"])
                        audio_clips.append(audio_clip)
                
                if audio_clips:
                    combined_audio = concatenate_audioclips(audio_clips)
                    duration = combined_audio.duration + 0.5  # 0.5ç§’ã®ä½™ç™½ã®ã¿
                    image_clip = image_clip.set_duration(duration).set_audio(combined_audio)
                else:
                    image_clip = image_clip.set_duration(3.0)
            else:
                image_clip = image_clip.set_duration(3.0)
            
            clips.append(image_clip)
        
        # å‹•ç”»ã‚’çµåˆ
        final_video = concatenate_videoclips(clips, method="compose")
        
        # å‡ºåŠ›è¨­å®šã‚’æœ€å°é™ã«
        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',  # AACã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã‚’ä½¿ç”¨
            verbose=False,
            logger=None
        )
        
        # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        final_video.close()
        for clip in clips:
            clip.close()
        
        return output_path
    
    def create_individual_slide_video(self, image_paths, dialogue_audio_info, output_path):
        """å€‹åˆ¥ã‚¹ãƒ©ã‚¤ãƒ‰ã§å‹•ç”»ä½œæˆã—ã¦ã‹ã‚‰çµåˆ"""
        print("ğŸ“¹ å€‹åˆ¥ã‚¹ãƒ©ã‚¤ãƒ‰ç‰ˆã§å‹•ç”»ä½œæˆä¸­...")
        temp_videos = []
        
        try:
            for i, image_path in enumerate(image_paths):
                slide_key = f"slide_{i+1}"
                audio_infos = dialogue_audio_info.get(slide_key, [])
                temp_video = f"temp_slide_{i+1}.mp4"
                
                # å„ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’å€‹åˆ¥ã«ä½œæˆ
                self.create_single_slide_video(image_path, audio_infos, temp_video)
                if self.check_video_integrity(temp_video):
                    temp_videos.append(temp_video)
                else:
                    print(f"âš ï¸  ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1} ã®å‹•ç”»ä½œæˆã«å¤±æ•—")
            
            if temp_videos:
                # ffmpegã§çµåˆ
                self.concat_videos_with_ffmpeg(temp_videos, output_path)
                return output_path
            else:
                raise Exception("ã™ã¹ã¦ã®ã‚¹ãƒ©ã‚¤ãƒ‰å‹•ç”»ã®ä½œæˆã«å¤±æ•—")
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            for temp_video in temp_videos:
                if os.path.exists(temp_video):
                    os.remove(temp_video)
    
    def create_single_slide_video(self, image_path, audio_infos, output_path):
        """å˜ä¸€ã‚¹ãƒ©ã‚¤ãƒ‰ã®å‹•ç”»ã‚’ä½œæˆ"""
        from moviepy.editor import ImageClip, AudioFileClip, concatenate_audioclips
        
        image_clip = ImageClip(image_path)
        
        if audio_infos:
            audio_clips = []
            for info in audio_infos:
                if info.get("audio_path") and Path(info["audio_path"]).exists():
                    audio_clip = AudioFileClip(info["audio_path"])
                    audio_clips.append(audio_clip)
            
            if audio_clips:
                combined_audio = concatenate_audioclips(audio_clips)
                duration = combined_audio.duration + 0.5
                image_clip = image_clip.set_duration(duration).set_audio(combined_audio)
            else:
                image_clip = image_clip.set_duration(3.0)
        else:
            image_clip = image_clip.set_duration(3.0)
        
        image_clip.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            verbose=False,
            logger=None
        )
        
        image_clip.close()
    
    def concat_videos_with_ffmpeg(self, video_paths, output_path):
        """ffmpegã§å‹•ç”»ã‚’çµåˆ"""
        # çµåˆãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        list_file = "concat_list.txt"
        with open(list_file, 'w') as f:
            for video_path in video_paths:
                f.write(f"file '{video_path}'\n")
        
        try:
            subprocess.run([
                'ffmpeg', '-f', 'concat', '-safe', '0', '-i', list_file, 
                '-c', 'copy', output_path, '-y'
            ], check=True, capture_output=True)
        finally:
            if os.path.exists(list_file):
                os.remove(list_file)
    
    def create_video_with_fallback(self, image_paths, dialogue_audio_info, base_output_path="smart_video"):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãã§å‹•ç”»ã‚’ä½œæˆ"""
        for i, (strategy_name, strategy_func) in enumerate(self.fallback_strategies):
            output_path = f"{base_output_path}_{i+1}.mp4"
            
            try:
                print(f"\nğŸ¬ æˆ¦ç•¥ {i+1}: {strategy_name}")
                strategy_func(image_paths, dialogue_audio_info, output_path)
                
                # å‹•ç”»ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                if self.check_video_integrity(output_path):
                    print(f"ğŸ‰ æˆåŠŸï¼å‹•ç”»ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {output_path}")
                    return output_path
                else:
                    print(f"âš ï¸  {strategy_name}ã§ä½œæˆã•ã‚ŒãŸå‹•ç”»ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
                    if os.path.exists(output_path):
                        os.remove(output_path)
            
            except Exception as e:
                print(f"âŒ {strategy_name}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                if os.path.exists(output_path):
                    os.remove(output_path)
        
        print("ğŸ˜ ã™ã¹ã¦ã®æˆ¦ç•¥ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return None

def main():
    print("=== ã‚¹ãƒãƒ¼ãƒˆå‹•ç”»ä½œæˆï¼ˆè‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰ ===")
    
    # ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—
    slides_dir = Path("slides")
    image_paths = sorted([str(p) for p in slides_dir.glob("slide_*.png")])
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æ§‹ç¯‰
    dialogue_audio_info = {}
    audio_dir = Path("audio_synced")
    
    # å¯¾è©±å½¢å¼ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã¿
    with open("dialogue_narration_synced.json", 'r', encoding='utf-8') as f:
        dialogue_data = json.load(f)
    
    # å„ã‚¹ãƒ©ã‚¤ãƒ‰ã®éŸ³å£°æƒ…å ±ã‚’æ§‹ç¯‰
    for slide_key in dialogue_data.keys():
        slide_num = int(slide_key.split("_")[1])
        dialogue_audio_info[slide_key] = []
        
        # è©²å½“ã™ã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        audio_files = sorted(audio_dir.glob(f"slide_{slide_num:03d}_*_*.wav"))
        
        for audio_file in audio_files:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è©±è€…ã‚’ç‰¹å®š
            parts = audio_file.stem.split("_")
            if len(parts) >= 4:
                speaker = parts[3]
                dialogue_audio_info[slide_key].append({
                    "speaker": speaker,
                    "audio_path": str(audio_file)
                })
    
    # ã‚¹ãƒãƒ¼ãƒˆå‹•ç”»ä½œæˆ
    creator = SmartVideoCreator()
    result = creator.create_video_with_fallback(
        image_paths, 
        dialogue_audio_info, 
        "claude_code_smart"
    )
    
    if result:
        print(f"\nâœ… æœ€çµ‚çš„ã«æˆåŠŸã—ãŸå‹•ç”»: {result}")
    else:
        print("\nâŒ å‹•ç”»ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()